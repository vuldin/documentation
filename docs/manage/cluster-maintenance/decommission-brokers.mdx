---
title: Decommission Brokers
deployment: Linux
linkRoot: ../../../
contextLinks:
  - name: 'Linux'
    to: 'manage/cluster-maintenance/decommission-brokers'
  - name: 'Kubernetes'
    to: manage/kubernetes/decommission-brokers
description: Remove a broker so that it is no longer considered part of the cluster.
---

<head>
    <meta name="title" content="Decommission Brokers | Redpanda Docs"/>
    <meta name="description" content="Remove a broker so that it is no longer considered part of the cluster."/>
    <link rel="canonical" href="https://docs.redpanda.com/docs/manage/cluster-maintenance/decommission-brokers/" />
</head>

import ContextLink from '@site/src/components/ContextButton.js'

<ContextLink frontmatter={frontMatter}
/>

When you decommission a broker, its partition replicas are reallocated across the remaining brokers and it is removed from the cluster. You may want to decommission a broker in the following circumstances:

- The broker has lost its storage and you need a new broker with a new node ID (broker ID).
- You are replacing a broker, for example to upgrade the Linux kernel or to replace the hardware.
- You are removing a broker to decrease the size of the cluster.

:::info
When a broker is decommissioned, it cannot rejoin the cluster. If a broker with the same ID tries to rejoin the cluster, it is rejected.
:::

## What happens when a broker is decommissioned?

When a broker is decommissioned, the controller leader creates a reallocation plan for all partition replicas that are allocated to that broker. By default, this reallocation is done in batches of 50 to avoid overwhelming the remaining brokers with Raft recovery. See [`partition_autobalancing_concurrent_moves`](../../../reference/tunable-properties#partition_autobalancing_concurrent_moves).

The reallocation of each partition is translated into a Raft group reconfiguration and executed by the controller leader. The partition leader then handles the reconfiguration for its Raft group. After the reallocation for a partition is complete, it is recorded in the controller log and the status is updated in the topic tables of each broker.

The decommissioning process is successful only when all partition reallocations have been completed successfully. The controller leader polls for the status of all the partition-level reallocations to ensure that everything completes as expected.

During the decommissioning process, new partitions are not allocated to the broker that is being decommissioned. After all the reallocations have been completed successfully, the broker is removed from the cluster.

:::note
The decommissioning process is designed to tolerate controller leadership transfers.
:::

:::tip
This guide uses `jq` to make parsing JSON output easier. If you want more details, see the [jq downloads page](https://stedolan.github.io/jq/download/).
:::

## Should you decommission brokers?

There are several considerations in order to determine your cluster's minimum broker count and to decide whether to decommission any brokers. As an example, this section focuses on a cluster with 7 brokers. In each section, the output from the given commands will provide further details to help determine the minimum number of brokers.

### Availability

You want enough brokers to properly span across each rack or availability zone. Run the following command in order to determine whether rack awareness is enabled in your cluster:

```bash
rpk cluster config get enable_rack_awareness
```

<details>
<summary>
Example output
</summary>

```
true
```

</details>

If enabled, then you should see which rack each broker is assigned to with the following command:

```bash
rpk cluster info
```

<details>
<summary>
Example output
</summary>

```
CLUSTER
=======
redpanda.560e2403-3fd6-448c-b720-7b456d0aa78c

BROKERS
=======
ID    HOST                          PORT   RACK
0     redpanda-0.testcluster.local  32180  A
1     redpanda-1.testcluster.local  32180  A
4     redpanda-3.testcluster.local  32180  B
5*    redpanda-2.testcluster.local  32180  B
6     redpanda-4.testcluster.local  32180  C
8     redpanda-6.testcluster.local  32180  C
9     redpanda-5.testcluster.local  32180  D
```

</details>

This shows we have four racks (A/B/C/D), so we may want to have at least 4 brokers in order to make use of all racks.

Rack awareness is just one aspect of availability. Check out [this guide](https://docs.redpanda.com/docs/deploy/deployment-option/self-hosted/manual/high-availability/) for more details on deploying Redpanda for high availability.

### Cost

Your infrastructure costs will increase with each broker, and adding a broker means an additional instance to pay for. In our example we are deploying to GKE on [n2-standard-8](https://gcloud-compute.com/n2-standard-8.html) GCP instances. This means that the instance cost of our cluster is &dollar;1925 per month. Dropping down to 5 brokers would save &dollar;550 per month, and dropping down to 3 brokers would save &dollar;1100 per month. There are other costs to consider of course, but they won't be as impacted by changing the broker count.

### Data retention test

Local data retention is determined by the storage capability of each broker and how much data is being produced over a given period (ie. producer throughput). When decommissioning, storage capability needs to take into account both the free storage space as well as the amount of a space already used by existing partitions.

Run the following command to determine how much storage is being used (in bytes) on each broker:

```bash
rpk cluster logdirs describe --aggregate-into broker
```

<details>
<summary>
Example output
</summary>

```
BROKER  SIZE          ERROR
0       263882790656
1       256177979648
2       257698037504
3       259934992896
4       254087316992
5       258369126144
6       255227998208
```

</details>

The example output shows that each broker contains roughly 240GB of data. This means scaling down to 5 brokers would require each broker to have at least 337GB to hold current data.

Throughput is the primary measurement required to calculate future data storage requirements. In our example cluster we have a throughput of 200MB/sec, which means we will generate 0.72TB/hour (or 17.28TB/day, or 120.96TB/wk). We can divide this amount by the target number of brokers to get an estimate of how much storage we need to retain that much data for various periods of time:

| Retention | Disk size (on each of the 5 brokers) |
| - | - |
| 30mins | `(200MB/sec * 30mins * 1.1) = 0.396TB / 5 brokers = 79.2GB` |
| 6hrs | `(200MB/sec * 6hrs * 1.1) = = 4.752TB / 5 brokers = 950.4GB` |
| 1d | `(200MB/sec * 1d * 1.1) = 19.008TB  / 5 brokers = 3.8TB` |
| 3d | `(200MB/sec * 3d * 1.1) = 57.024TB / 5 brokers = 11.4TB` |

In our example cluster we only need to retain 6 hours of data locally (and any older data is moved to tiered storage with a retention of 1 year). So we will need to ensure each broker has available storage of around 1.2TB (taking into account both throughput and current data).

Cost and your use case requirements will dictate how much to spend on local disk capacity. Tiered storage can help with both decreasing costs and expanding data retention capabilities. More details [here](https://docs.redpanda.com/docs/manage/tiered-storage/).

:::note
At this point in the example we don't know for sure that we can scale down to 5 brokers. But we are calculating based on 5 brokers for now, and later we can use other broker counts as needed.
:::

:::note
Some assumption were made regarding a constant throughput and perfect data balancing. In reality, throughput fluctuates across all partitions which causes data imbalance. The calculations above attempted to accomodate this by padding disk size by 1%, and this buffer can be increased (in the case of expected hot spot partitions, for example). For more details on sizing, see [this link](https://docs.redpanda.com/docs/deploy/deployment-option/self-hosted/manual/sizing/).
:::


### Durability


The brokers in a Redpanda cluster are part of a raft group that requires at least enough brokers to form a quorum-based majority (which would mean 3 brokers at minimum). Each topic's partitions are also raft groups, so your cluster also needs to have at least as many brokers as the lowest replication factor across all topics. One way to find the max replication factor across all topics in your cluster is the following command:

```bash
rpk topic list | tail -n +2 | awk '{print $3}' | sort -n | tail -1
```

<details>
<summary>
Example output
</summary>

```
5
```

</details>

In this example the highest replication factor is 5, which means we will need at least 5 brokers in our cluster.

In general your cluster will withstand a higher number of brokers going down if you have more brokers as part of the cluster. See [this link](https://docs.redpanda.com/docs/get-started/architecture/#raft-consensus-algorithm) for more details on the raft consensus algorithm used by Redpanda.

### Partition count

In general, make sure your total partition count does not exceed 1K per core. In practice this max partition count depends on many other factors (such as memory per core, CPU performance, throughput, latency requirements, etc.). But going over 1K partitions per core can lead to issues such as increased latency, increased number of partition leadership elections, and general reduced stability. Run the following command to get your total partition count:

```bash
curl -sk http://<broker-url>:<admin-api-port>/v1/partitions/local_summary | jq .count
```

<details>
<summary>
Example output
</summary>

```
3018
```

</details>

Now you need to determine the number of cores you will have available across your remaining brokers:

```bash
rpk redpanda admin brokers list
```

<details>
<summary>
Example output
</summary>

```
NODE-ID  NUM-CORES  MEMBERSHIP-STATUS  IS-ALIVE  BROKER-VERSION
0        8          active             true      v23.1.8 - e8cf768bdff324f947ba067219c9c9a3a559b248
1        8          active             true      v23.1.8 - e8cf768bdff324f947ba067219c9c9a3a559b248
2        8          active             true      v23.1.8 - e8cf768bdff324f947ba067219c9c9a3a559b248
3        8          active             true      v23.1.8 - e8cf768bdff324f947ba067219c9c9a3a559b248
4        8          active             true      v23.1.8 - e8cf768bdff324f947ba067219c9c9a3a559b248
5        8          active             true      v23.1.8 - e8cf768bdff324f947ba067219c9c9a3a559b248
6        8          active             true      v23.1.8 - e8cf768bdff324f947ba067219c9c9a3a559b248
```

</details>

In the above example each broker has 12 cores available. If you plan to scale down the number of brokers to 5, then you would have 40 cores available. This means that your cluster will be limited by core count to 40K partitions (well above the current 3018 partitions).

:::note
In order to best ensure stability of the cluster, keep under 50K partitions per cluster.
:::

### Decommission verdict

Here are the details of each considerations above:

- At least 4 brokers based on availability
- Cost won't be a limiting factor in this example, but less cost (and lower broker count) is better
- At least 1.2TB of data on each broker (if spreading across 5 brokers). This falls within the 1.5TB of local storage available in our example.
- At least 5 brokers based on the highest replication factor across all topics
- At 3018 partitions, the partition count is so low as to not be a determining factor in broker count (a single broker in our example environment could handle many more partitions)

So the most limiting consideration is the replication factor of 5, meaning we can scale down to 5 brokers at minimum.

## Decommission a broker

1. List your brokers and their associated broker IDs:

  ```bash
  rpk cluster info \
    --brokers <broker-url>:<kafka-api-port>
  ```

1. Decommission the broker with your selected broker ID:

  ```bash
  rpk redpanda admin brokers decommission <broker-id> \
    --hosts <broker-url>:<admin-api-port> \
    --force
  ```

  :::note
  The `--force` flag is required only if the broker is not running.
  :::

  If you see `Success, broker <broker-id> has been decommissioned!`, the broker is decommissioned. Otherwise, the decommissioning process is still in progress. You can monitor the decommissioning status to follow its progress.

1. Monitor the decommissioning status:

  ```bash
  rpk redpanda admin brokers decommission-status <broker-id> \
    --api-urls <broker-url>:<admin-api-port>
  ```

  The output uses cached cluster health data that is refreshed every 10 seconds.

When the completion column for all rows is 100%, the broker is decommissioned.

:::info
If you add a new broker, make sure to give it a unique ID. Do not reuse the ID of the decommissioned broker.
:::

## Troubleshooting

If the decommissioning process is not making progress, investigate the following potential issues:

- **Absence of a controller leader or partition leader**: The controller leader serves as the orchestrator for decommissioning. Additionally, if one of the partitions undergoing reconfiguration does not have a leader, the reconfiguration process may stall. Make sure that an elected leader is present for all partitions.

- **Bandwidth limitations for partition recovery**: Try increasing the value of [`raft_learner_recovery_rate`](../../../reference/cluster-properties#raft_learner_recovery_rate), and monitor the status using the [`redpanda_raft_recovery_partition_movement_available_bandwidth`](../../../reference/public-metrics-reference#redpanda_raft_recovery_partition_movement_available_bandwidth) metric.

If these steps do not allow the decommissioning process to complete, enable `TRACE` level logging on the controller leader to investigate any other issues.

## Suggested reading

- [`rpk-redpanda-admin-brokers-decommission`](../../../reference/rpk/rpk-redpanda/rpk-redpanda-admin-brokers-decommission)

- [Engineering a more robust Raft group reconfiguration](https://redpanda.com/blog/raft-protocol-reconfiguration-solution)
